{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketized reviews with keywords saved to bucketized_bajaj_avenger_220_street_reviews_with_keywords.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch  # Import PyTorch\n",
    "\n",
    "# Load models\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')  # For extracting keywords\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # For semantic similarity\n",
    "\n",
    "# Buckets\n",
    "buckets = [\n",
    "    \"Alloy\", \"Bluetooth\", \"Clearance\", \"Color\", \"Comfort\", \"Console\", \"Dealer\",\n",
    "    \"Engine\", \"Engine performance\", \"Engine sound\", \"Mileage\", \"Experience\", \"Exterior\",\n",
    "    \"Fuel efficiency\", \"Gear\", \"Gearbox\", \"Performance\", \"Suspension\", \"Ground clearance\",\n",
    "    \"Headlamp\", \"Insurance\", \"KMPL\", \"LED\", \"Lights\", \"Looks\", \"Luggage\", \"Maintenance\",\n",
    "    \"Maintenance cost\", \"Navigation\", \"Pickup\", \"Power\", \"Price\", \"RPM\", \"Rear\",\n",
    "    \"Rear seat\", \"Safety\", \"Safety feature\", \"Seat\", \"Seat cover\", \"Service\",\n",
    "    \"Service center\", \"Service cost\", \"Showroom\", \"Spare part\", \"Speed\", \"Style\",\n",
    "    \"Test drive\", \"Torque\", \"Transmission\", \"Turning radius\", \"Tyres\", \"Vent\", \"Wheel\", \"Boot\"\n",
    "]\n",
    "\n",
    "# File details\n",
    "file_path = \"bajaj_avenger_220_street_reviews.csv\"  # Replace with your actual file name\n",
    "bike_name = \" \".join(file_path.split(\"_\")[:-1])  # Extract bike name from file name (without 'reviews')\n",
    "bike_name_words = bike_name.lower().split()  # Split bike name into individual words\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'Review_Text' column exists\n",
    "if 'Review_Text' not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain a 'Review_Text' column.\")\n",
    "\n",
    "# Function to extract keywords for a single review\n",
    "def extract_keywords_without_bike_name(text, bike_name_words, top_n=5):\n",
    "    if pd.isna(text):  # Handle missing or NaN values\n",
    "        return []\n",
    "    \n",
    "    # Extract keywords using KeyBERT\n",
    "    keywords = kw_model.extract_keywords(text, \n",
    "                                         keyphrase_ngram_range=(1, 2), \n",
    "                                         stop_words='english', \n",
    "                                         top_n=top_n)\n",
    "    \n",
    "    # Filter out bike name words from the keywords\n",
    "    filtered_keywords = [\n",
    "        keyword for keyword, score in keywords \n",
    "        if not any(word in keyword.lower() for word in bike_name_words)\n",
    "    ]\n",
    "    return filtered_keywords\n",
    "\n",
    "# Function to find the best matching bucket\n",
    "def assign_bucket(keywords, buckets, embedding_model):\n",
    "    if not keywords:  # No keywords extracted\n",
    "        return \"Other\"\n",
    "    \n",
    "    # Generate embeddings for buckets\n",
    "    bucket_embeddings = embedding_model.encode(buckets, convert_to_tensor=True)\n",
    "\n",
    "    for keyword in keywords:\n",
    "        keyword_embedding = embedding_model.encode(keyword, convert_to_tensor=True)\n",
    "        # Compute similarity scores\n",
    "        similarities = util.pytorch_cos_sim(keyword_embedding, bucket_embeddings)\n",
    "        max_similarity, best_bucket_index = torch.max(similarities, dim=1)\n",
    "\n",
    "        # Check if the similarity is significant\n",
    "        if max_similarity.item() > 0.5:  # Threshold for match\n",
    "            return buckets[best_bucket_index.item()]\n",
    "    \n",
    "    return \"Other\"  # If no match found\n",
    "\n",
    "# Apply the functions to extract keywords and assign buckets\n",
    "df['Keywords'] = df['Review_Text'].apply(\n",
    "    lambda x: extract_keywords_without_bike_name(x, bike_name_words, top_n=5)\n",
    ")\n",
    "df['Assigned_Bucket'] = df['Keywords'].apply(\n",
    "    lambda x: assign_bucket(x, buckets, embedding_model)\n",
    ")\n",
    "\n",
    "# Convert keywords to a string for better readability in the output\n",
    "df['Keywords'] = df['Keywords'].apply(lambda x: \", \".join(x) if x else \"\")\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_file = \"bucketized_bajaj_avenger_220_street_reviews_with_keywords.csv\"\n",
    "df[['Keywords', 'Assigned_Bucket', 'Review_Text']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Bucketized reviews with keywords saved to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
