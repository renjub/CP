{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 12:19:43.198991: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 12:19:43.247445: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 12:19:43.248599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 12:19:44.098239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './TodoSentiment.list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 113\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Specify the file containing the list of CSV files to process\u001b[39;00m\n\u001b[1;32m    112\u001b[0m file_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./TodoSentiment.list\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your list file\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[43mprocess_all_csv_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 70\u001b[0m, in \u001b[0;36mprocess_all_csv_files\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_all_csv_files\u001b[39m(file_list):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     71\u001b[0m         files \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "File \u001b[0;32m/datadrive/cp_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './TodoSentiment.list'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Function for BERT sentiment analysis using Hugging Face transformers\n",
    "def bert_sentiment(text):\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    label = result['label'].lower()\n",
    "    score = result['score']\n",
    "    # Convert label to positive, negative, or neutral\n",
    "    if \"1 star\" in label or \"2 stars\" in label:\n",
    "        sentiment = \"negative\"\n",
    "    elif \"4 stars\" in label or \"5 stars\" in label:\n",
    "        sentiment = \"positive\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    return sentiment, score, \"BERT\"\n",
    "\n",
    "# Function for Flair sentiment analysis\n",
    "def flair_sentiment(text):\n",
    "    classifier = TextClassifier.load('en-sentiment')\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "    label = sentence.labels[0].value.lower()\n",
    "    score = sentence.labels[0].score\n",
    "    return label, score, \"Flair\"\n",
    "\n",
    "# Function for DistilBERT sentiment analysis\n",
    "def distilbert_sentiment(text):\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    sentiment = result['label'].lower()\n",
    "    score = result['score']\n",
    "    return sentiment, score, \"DistilBERT\"\n",
    "\n",
    "# Function to determine which model to use based on text length\n",
    "def sentiment_analysis(text):\n",
    "    # Tokenize text to determine length\n",
    "    token_length = len(text.split())\n",
    "    \n",
    "    # If token length is <= 512, use BERT\n",
    "    if token_length <= 512:\n",
    "        try:\n",
    "            return bert_sentiment(text)\n",
    "        except Exception as e:\n",
    "            print(f\"BERT failed with error: {e}\")\n",
    "    \n",
    "    # If token length exceeds 512, or BERT fails, use Flair\n",
    "    if token_length > 512 or torch.cuda.is_available() == False:\n",
    "        try:\n",
    "            return flair_sentiment(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Flair failed with error: {e}\")\n",
    "    \n",
    "    # If Flair also fails, use DistilBERT\n",
    "    try:\n",
    "        return distilbert_sentiment(text)\n",
    "    except Exception as e:\n",
    "        print(f\"DistilBERT failed with error: {e}\")\n",
    "\n",
    "    # If all models fail, return neutral sentiment\n",
    "    return \"neutral\", 0.0, \"None\"\n",
    "\n",
    "# Function to process all CSV files in the list\n",
    "def process_all_csv_files(file_list):\n",
    "    with open(file_list, 'r') as f:\n",
    "        files = [line.strip() for line in f.readlines()]\n",
    "        for file_path in files:\n",
    "            if os.path.exists(file_path) and file_path.endswith('.csv'):\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "                process_csv_file(file_path)\n",
    "            else:\n",
    "                print(f\"Skipping invalid or missing file: {file_path}\")\n",
    "\n",
    "# Function to process a single CSV file\n",
    "def process_csv_file(input_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Assuming the review text is in columns named 'Title' and 'Review'\n",
    "    df['Title'] = df['Title'].astype(str).fillna('')  # Ensure all values are strings and handle missing values\n",
    "    df['Review'] = df['Review'].astype(str).fillna('')\n",
    "\n",
    "    sentiments = []\n",
    "    scores = []\n",
    "    methods = []\n",
    "    for title, review in zip(df['Title'], df['Review']):\n",
    "        combined_text = f\"{title} {review}\".strip()  # Combine title and review text\n",
    "        if combined_text:  # Ensure combined text is non-empty\n",
    "            sentiment, score, method = sentiment_analysis(combined_text)\n",
    "        else:\n",
    "            sentiment, score, method = \"neutral\", 0.0, \"None\"  # Handle empty or invalid combined text\n",
    "        sentiments.append(sentiment)\n",
    "        scores.append(score)\n",
    "        methods.append(method)\n",
    "\n",
    "    # Adding the sentiment, value, and method columns to the DataFrame\n",
    "    df['Sentiment'] = sentiments\n",
    "    df['Value'] = scores\n",
    "    df['Method Used'] = methods\n",
    "\n",
    "    # Saving the updated DataFrame to the same CSV file\n",
    "    df.to_csv(input_csv, index=False)\n",
    "\n",
    "    # Displaying the updated DataFrame as a table\n",
    "    print(df)\n",
    "\n",
    "# Specify the file containing the list of CSV files to process\n",
    "file_list = \"./TodoSentiment.list\"  # Replace with the path to your list file\n",
    "process_all_csv_files(file_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
