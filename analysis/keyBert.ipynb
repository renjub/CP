{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords and Review_Text saved to output_bajaj_avenger_220_street_keywords.csv in the correct order.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load KeyBERT and SBERT models\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')  # For keyword extraction\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')  # For semantic similarity\n",
    "\n",
    "# File details\n",
    "file_path = \"bajaj_avenger_220_street_reviews.csv\"  # Replace with your actual file name\n",
    "bike_name = \" \".join(file_path.split(\"_\")[:-1])  # Extract bike name from file name (without 'reviews')\n",
    "bike_name_words = bike_name.lower().split()  # Split bike name into individual words\n",
    "\n",
    "# List of buckets\n",
    "buckets = [\n",
    "    \"Alloy\", \"Bluetooth\", \"Clearance\", \"Color\", \"Comfort\", \"Console\", \"Dealer\",\n",
    "    \"Engine\", \"Engine performance\", \"Engine sound\", \"Mileage\", \"Experience\", \"Exterior\",\n",
    "    \"Fuel efficiency\", \"Gear\", \"Gearbox\", \"Performance\", \"Suspension\", \"Ground clearance\",\n",
    "    \"Headlamp\", \"Insurance\", \"KMPL\", \"LED\", \"Lights\", \"Looks\", \"Luggage\", \"Maintenance\",\n",
    "    \"Maintenance cost\", \"Navigation\", \"Pickup\", \"Power\", \"Price\", \"RPM\", \"Rear\",\n",
    "    \"Rear seat\", \"Safety\", \"Safety feature\", \"Seat\", \"Seat cover\", \"Service\",\n",
    "    \"Service center\", \"Service cost\", \"Showroom\", \"Spare part\", \"Speed\", \"Style\",\n",
    "    \"Test drive\", \"Torque\", \"Transmission\", \"Turning radius\", \"Tyres\", \"Vent\", \"Wheel\", \"Boot\"\n",
    "]\n",
    "bucket_embeddings = sbert_model.encode(buckets, convert_to_tensor=True)  # Pre-compute bucket embeddings\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'Review_Text' column exists\n",
    "if 'Review_Text' not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain a 'Review_Text' column.\")\n",
    "\n",
    "# Function to extract top keyword and categorize it\n",
    "def categorize_top_keyword(text, bike_name_words, bucket_embeddings, buckets, top_n=5):\n",
    "    if pd.isna(text):  # Handle missing or NaN values\n",
    "        return \"others\", \"\"\n",
    "    \n",
    "    # Extract keywords using KeyBERT\n",
    "    keywords = kw_model.extract_keywords(text, \n",
    "                                         keyphrase_ngram_range=(1, 2), \n",
    "                                         stop_words='english', \n",
    "                                         top_n=top_n)\n",
    "    \n",
    "    # Filter out bike name words\n",
    "    filtered_keywords = [\n",
    "        keyword for keyword, score in keywords \n",
    "        if not any(word in keyword.lower() for word in bike_name_words)\n",
    "    ]\n",
    "    \n",
    "    if filtered_keywords:\n",
    "        # Take the top keyword\n",
    "        top_keyword = filtered_keywords[0][0]  # First keyword (string)\n",
    "        \n",
    "        # Compute similarity between the top keyword and buckets\n",
    "        keyword_embedding = sbert_model.encode(top_keyword, convert_to_tensor=True)\n",
    "        similarities = util.pytorch_cos_sim(keyword_embedding, bucket_embeddings)[0]\n",
    "        \n",
    "        # Find the best matching bucket\n",
    "        best_bucket_idx = similarities.argmax().item()\n",
    "        best_bucket = buckets[best_bucket_idx]\n",
    "        similarity_score = similarities[best_bucket_idx].item()\n",
    "        \n",
    "        # If similarity is above a threshold, assign the bucket; otherwise, 'others'\n",
    "        return (best_bucket if similarity_score > 0.5 else \"others\", top_keyword)\n",
    "    \n",
    "    return \"others\", \"\"\n",
    "\n",
    "# Apply the function to the 'Review_Text' column\n",
    "df[['Bucket', 'Top_Keyword']] = df['Review_Text'].apply(\n",
    "    lambda x: pd.Series(categorize_top_keyword(x, bike_name_words, bucket_embeddings, buckets, top_n=5))\n",
    ")\n",
    "\n",
    "# Rearrange columns to Bucket, Top_Keyword, and Review_Text\n",
    "df = df[['Bucket', 'Top_Keyword', 'Review_Text']]\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_file = \"output_bajaj_avenger_220_street_keywords_with_buckets.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Keywords categorized into buckets based on meaning and saved to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
