{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next button not found, or no more pages. Exiting.\n",
      "Clicked on the 'Next' button.\n",
      "Clicked on the 'Next' button.\n",
      "Clicked on the 'Next' button.\n",
      "Clicked on the 'Next' button.\n",
      "Next button not found, or no more pages. Exiting.\n",
      "Reviews extraction complete. Data saved to 'mouthshut_reviews_with_dynamic_website.csv'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd  # Import pandas for DataFrame\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Function to extract star rating from the review_div\n",
    "def extract_star_rating_from_review(review_div):\n",
    "    \"\"\"\n",
    "    This function takes in the review_div, finds the div that contains the star rating,\n",
    "    and counts the number of rated stars (elements with the 'icon-rating rated-star' class).\n",
    "    Returns the star rating (integer). If no rating_div is found, it returns 0.\n",
    "    \"\"\"\n",
    "    rating_div = review_div.find('div', class_='rating')\n",
    "    \n",
    "    if rating_div:\n",
    "        star_span = rating_div.find('span', recursive=False)\n",
    "        if star_span:\n",
    "            rated_stars = star_span.find_all('i', class_='icon-rating rated-star')\n",
    "            star_rating = len(rated_stars)\n",
    "        else:\n",
    "            star_rating = 0\n",
    "    else:\n",
    "        star_rating = 0\n",
    "    \n",
    "    return star_rating\n",
    "\n",
    "# Function to extract review text from the review_div\n",
    "def extract_review_text(review_div):\n",
    "    \"\"\"\n",
    "    This function takes in the review_div and extracts the review text from the 'p' tag inside the 'div.more.reviewdata'.\n",
    "    Returns the review text as a string or a default message if not available.\n",
    "    \"\"\"\n",
    "    review_element = review_div.select_one(\"div.more.reviewdata > p\")\n",
    "    \n",
    "    if review_element:\n",
    "        review_text = review_element.get_text(strip=True)\n",
    "    else:\n",
    "        review_text = \"No review text available.\"\n",
    "    \n",
    "    return review_text\n",
    "\n",
    "# Function to extract date and time from the review_div\n",
    "def extract_review_datetime(review_div):\n",
    "    \"\"\"\n",
    "    This function takes in the review_div and extracts the date and time from the element\n",
    "    with the id '#rptreviews_ctl00_lblDateTime'.\n",
    "    Returns the date and time as a string or a default message if not available.\n",
    "    \"\"\"\n",
    "    datetime_element = review_div.find('span', id=re.compile(r'^rptreviews_ctl\\d+_lblDateTime$'))\n",
    "    \n",
    "    if datetime_element:\n",
    "        review_datetime = datetime_element.get_text(strip=True)\n",
    "    else:\n",
    "        review_datetime = \"No date and time available.\"\n",
    "    \n",
    "    return review_datetime\n",
    "\n",
    "# Function to extract the number of likes from the review_div\n",
    "def extract_review_likes(review_div):\n",
    "    \"\"\"\n",
    "    This function takes in the review_div and extracts the number of likes from the element\n",
    "    with the id matching '#rptreviews_ctl00_divlike > a'.\n",
    "    Returns the number of likes as an integer or 0 if not available.\n",
    "    \"\"\"\n",
    "    likes_element = review_div.find('a', id=re.compile(r'^rptreviews_ctl\\d+_divlike$'))\n",
    "    \n",
    "    if likes_element:\n",
    "        likes_text = likes_element.get_text(strip=True)\n",
    "        likes = int(re.search(r'\\d+', likes_text).group()) if re.search(r'\\d+', likes_text) else 0\n",
    "    else:\n",
    "        likes = 0\n",
    "    \n",
    "    return likes\n",
    "\n",
    "# Main extraction function\n",
    "def extract(driver):\n",
    "    review_count = 0\n",
    "    max_reviews  = 9999999  # Set your desired number of reviews here\n",
    "    all_reviews  = []  # Store extracted reviews here\n",
    "\n",
    "    #----------------------------Extract Reviews from Current Page----------------------------\n",
    "    while True:\n",
    "        # Wait until the page is loaded\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Use regex to find all divs with ids matching the pattern\n",
    "        pattern = re.compile(r'^rptreviews_ctl\\d+_lireviewdetails$')\n",
    "        review_divs = soup.find_all('div', id=pattern)\n",
    "\n",
    "        #----------------------------Extract----------------------------\n",
    "        for review_div in review_divs:\n",
    "            # Extract review details\n",
    "            review_text = extract_review_text(review_div)\n",
    "            star_rating = extract_star_rating_from_review(review_div)\n",
    "            review_datetime = extract_review_datetime(review_div)\n",
    "            \n",
    "            # Append the extracted information as a dictionary\n",
    "            all_reviews.append({\n",
    "                'Rating': star_rating,\n",
    "                'Review Text': review_text,\n",
    "                'Date and Time': review_datetime\n",
    "            })\n",
    "\n",
    "        review_count += len(review_divs)\n",
    "\n",
    "        #----------------------------Exit Conditions----------------------------\n",
    "        # If review count exceeds max_reviews, stop extraction\n",
    "        if review_count >= max_reviews:\n",
    "            print(\"Desired number of reviews loaded. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Check if the 'Next' button is available\n",
    "        next_button_elements = driver.find_elements(By.CSS_SELECTOR, \"#litPages > ul > li.next > a\")\n",
    "        if next_button_elements:\n",
    "            next_button = next_button_elements[0]\n",
    "            # Click the 'Next' button to go to the next page of reviews\n",
    "            ActionChains(driver).move_to_element(next_button).click(next_button).perform()\n",
    "            print(\"Clicked on the 'Next' button.\")\n",
    "            \n",
    "            # Wait for the content to load after clicking the button\n",
    "            time.sleep(2)  # Adjust if necessary\n",
    "        else:\n",
    "            print(\"Next button not found, or no more pages. Exiting.\")\n",
    "            break\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "\n",
    "# Function to extract the domain name (website) from a URL\n",
    "def extract_website(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    return parsed_url.netloc\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure ChromeDriver is set up correctly\n",
    "\n",
    "# Load the CSV file with the links\n",
    "file_path = 'extracted_links.csv'  # Update this with the correct path\n",
    "extracted_links_df = pd.read_csv(file_path)\n",
    "\n",
    "# Iterate through each link in the extracted_links_df\n",
    "all_data = []\n",
    "for index, row in extracted_links_df.iterrows():\n",
    "    url = row['Link']\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Extract reviews\n",
    "    extracted_data = extract(driver)\n",
    "    \n",
    "    # Extract the website from the URL\n",
    "    website = extract_website(url)\n",
    "    \n",
    "    # Add the product name and website to each review\n",
    "    for data in extracted_data:\n",
    "        data['Product'] = row['Text']\n",
    "        data['Website'] = website\n",
    "    \n",
    "    all_data.extend(extracted_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "reviews_df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the reviews to a CSV file\n",
    "reviews_df.to_csv('extracted_reviews.csv', index=False)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Reviews extraction complete. Data saved to 'extracted_reviews.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
