{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews to load: 25\n",
      "Current reviews displayed: 4\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 8\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 12\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 16\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 20\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 24\n",
      "Clicked on the 'Load More Reviews' button.\n",
      "Current reviews displayed: 25\n",
      "All reviews are loaded. Exiting the function.\n",
      "Reviews saved to bajaj_avenger_220_street_reviews.csv.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_total_review_count(page):\n",
    "    try:\n",
    "        # Get the page content and parse it with BeautifulSoup\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Use the provided CSS selector to extract the desired element\n",
    "        element = soup.select_one('body > main > div > div > div.pull-left.bodyLeft > div.ur-mct.rcat > div.col-lg-4.col-md-4.col-sm-4.col-xs-12 > div > div > div.clr-bl.ur-rc > div.fnt-12.clr.clr-sry.pull-left')\n",
    "\n",
    "        # Extract the text content, if the element exists\n",
    "        if element:\n",
    "            text = element.get_text(strip=True)\n",
    "            # Use regex to find the number of reviews in the format \"Based on X reviews\"\n",
    "            match = re.search(r'Based on (\\d+) reviews', text)\n",
    "            if match:\n",
    "                return int(match.group(1))  # Return the number of reviews as an integer\n",
    "            else:\n",
    "                print(\"Number of reviews not found in the text.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Element not found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching total reviews: {e}\")\n",
    "        return None\n",
    "\n",
    "# Modified function to click the 'Load More Reviews' button until all reviews are loaded\n",
    "async def click_load_more_review_button(page, bike_name):\n",
    "    # Get the total number of reviews from the specified element\n",
    "    total_reviews = await get_total_review_count(page)\n",
    "    if total_reviews is None:\n",
    "        print(\"Could not fetch the total number of reviews. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Total reviews to load: {total_reviews}\")\n",
    "    print(f\"Total reviews to load for '{bike_name}': {total_reviews}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Get the current number of reviews displayed inside #userReviews8\n",
    "            review_blocks = await page.query_selector_all('#userReviews8 [id^=\"overflow_hidden_\"]')\n",
    "            current_reviews_count = len(review_blocks)\n",
    "            print(f\"Current reviews displayed: {current_reviews_count}\")\n",
    "\n",
    "            # Stop if the current number of reviews equals or exceeds the total reviews\n",
    "            if current_reviews_count >= total_reviews:\n",
    "                print(\"All reviews are loaded. Exiting the function.\")\n",
    "                break\n",
    "\n",
    "            # Check if the 'Load More Reviews' button inside #userReviews8 is visible\n",
    "            load_more_button = await page.query_selector('#loadMore8')  # Updated selector for Load More button\n",
    "            if load_more_button:\n",
    "                # Scroll to the button and click it\n",
    "                await load_more_button.scroll_into_view_if_needed()\n",
    "                await load_more_button.click()\n",
    "                print(\"Clicked on the 'Load More Reviews' button.\")\n",
    "                \n",
    "                # Wait for the content to load after clicking the button\n",
    "                await asyncio.sleep(3)\n",
    "            else:\n",
    "                print(\"No more 'Load More Reviews' button found. Exiting the function.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "async def get_reviews(page):\n",
    "    # Get the page content\n",
    "    page_source = await page.content()\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Initialize a list to store all reviews\n",
    "    all_reviews = []\n",
    "\n",
    "    # Select the review blocks\n",
    "    review_blocks = soup.select('#userReviews8 [id^=\"overflow_hidden_\"]')\n",
    "\n",
    "    for block in review_blocks:\n",
    "        # Initialize a dictionary to store the review data\n",
    "        review_data = {}\n",
    "\n",
    "        # Handle multiple selectors for 'Top ZW Voice'\n",
    "        top_zw_voice = block.select_one('div > div.col-sm-2.nc-ndc.remove-clr > div.ndc-mr > span.fnt-12.clr-sry') or \\\n",
    "                       block.select_one('div > div.col-sm-2.nc-ndc.remove-clr > div.ndc-mr.pt-10 > span.fnt-12.clr-sry')\n",
    "\n",
    "        badge = block.select_one('div > div.col-sm-2.nc-ndc.remove-clr > div.ndc-mr > div > span > span')\n",
    "\n",
    "        # Handle both possible selectors for the title\n",
    "        title = block.select_one('div > div.col-sm-10.col-xs-12 > div > div.f-rv-des.mb-10.clr-bl > div.row.clr > div.col-sm-10.col-xs-10 > p') or \\\n",
    "                block.select_one('div > div.col-sm-10.col-xs-12 > div > div.row.clr > div.col-sm-10.col-xs-10 > p')\n",
    "\n",
    "        # Handle both possible selectors for review text\n",
    "        review_text = block.select_one('div > div.col-sm-10.col-xs-12 > div > div.f-rv-des.mb-10.clr-bl > div.read-more.ht-4lines.rm > p') or \\\n",
    "                      block.select_one('div > div.col-sm-10.col-xs-12 > div > div.read-more > p')\n",
    "\n",
    "        likes = block.select_one('[id^=\"review_\"]')\n",
    "\n",
    "        # Capture star rating\n",
    "        star_rating = block.select_one('div > div.col-sm-10.col-xs-12 > div > div.f-rv-des.mb-10.clr-bl > div.row.clr > div.col-sm-2.col-xs-2.text-right.pl-0.pr-0 > span > span')\n",
    "\n",
    "        # Store the extracted data in the dictionary, replacing None with \"-\"\n",
    "        review_data['Top_ZW_Voice'] = top_zw_voice.get_text(strip=True) if top_zw_voice else \"-\"\n",
    "        review_data['Badge']        = badge.get_text(strip=True) if badge else \"-\"\n",
    "        review_data['Title']        = title.get_text(strip=True) if title else \"-\"\n",
    "        review_data['Review_Text']  = review_text.get_text(strip=True) if review_text else \"-\"\n",
    "        review_data['Likes']        = likes.get_text(strip=True) if likes else \"-\"\n",
    "        review_data['Star_Rating']  = star_rating.get_text(strip=True) if star_rating else \"-\"\n",
    "\n",
    "        # Append the review data to the list of all reviews\n",
    "        all_reviews.append(review_data)\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Function to save reviews to a CSV file\n",
    "def save_reviews_to_csv(reviews, file_name):\n",
    "    # Define the headers for the CSV file\n",
    "    headers = ['Top_ZW_Voice', 'Badge', 'Title', 'Review_Text', 'Likes', 'Star_Rating']\n",
    "    \n",
    "    # Open the file in write mode to overwrite existing content\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        # Use csv.QUOTE_ALL to handle multiline text\n",
    "        writer = csv.DictWriter(file, fieldnames=headers, quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writeheader()\n",
    "        # Write each review (dictionary) to the CSV\n",
    "        for review in reviews:\n",
    "            writer.writerow(review)\n",
    "\n",
    "\n",
    "\n",
    "# Function to read URLs and bike names from allUrl.csv\n",
    "def read_urls_from_csv(file_name):\n",
    "    urls = []\n",
    "    with open(file_name, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            url = row.get('Link')\n",
    "            bike_name = row.get('Text')\n",
    "            if url and bike_name:\n",
    "                urls.append((url, bike_name))\n",
    "            else:\n",
    "                print(f\"Missing URL or BikeName in row: {row}\")\n",
    "    return urls\n",
    "\n",
    "# Main function to scrape reviews and save them to CSV\n",
    "async def scrape_reviews(url, bike_name, file_name):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        # Load the webpage\n",
    "        await page.goto(url)\n",
    "\n",
    "        # Click the 'Load More Reviews' button until all reviews are loaded\n",
    "        await click_load_more_review_button(page, bike_name)\n",
    "\n",
    "        # Extract reviews and save them after each page load\n",
    "        all_reviews = await get_reviews(page)\n",
    "        \n",
    "        # Save the reviews to CSV\n",
    "        if all_reviews:\n",
    "            save_reviews_to_csv(all_reviews, file_name)\n",
    "\n",
    "        print(f\"Reviews for '{bike_name}' saved to {file_name}.\")\n",
    "        \n",
    "        # Close the browser\n",
    "        await browser.close()\n",
    "\n",
    "# Main function to scrape reviews for multiple bikes\n",
    "async def main():\n",
    "    urls = read_urls_from_csv('allUrls_temp.csv')\n",
    "    tasks = []\n",
    "    for url, bike_name in urls:\n",
    "        file_name = f\"{bike_name.replace(' ', '_').lower()}_reviews.csv\"\n",
    "        task = scrape_reviews(url, bike_name, file_name)\n",
    "        tasks.append(task)\n",
    "    # Run all the tasks concurrently\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
