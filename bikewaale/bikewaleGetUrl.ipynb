{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished extracting the links and texts from all pages using Playwright.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Function to extract links and their text from the current page\n",
    "def extract_links(page_content):\n",
    "    all_links = []\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    # Find all the links matching the general pattern\n",
    "    link_elements = soup.select(\"div.USCqPI ul li > div > div > div > div.o-fznJEv.o-bTDyCI.o-brXWGL > a > h3\")\n",
    "\n",
    "    # Extract the href attribute and text for each link\n",
    "    for link_element in link_elements:\n",
    "        parent = link_element.find_parent('a')  # Find the parent <a> tag to extract the href\n",
    "        link = parent.get('href') if parent else None\n",
    "        text = link_element.get_text(strip=True)\n",
    "        if link and text:\n",
    "            # Convert relative link to absolute URL\n",
    "            absolute_link = urljoin('https://www.bikewale.com', link)\n",
    "            # Append '/review/' at the end of the link\n",
    "            absolute_link_with_review = absolute_link.rstrip('/') + '/reviews/'\n",
    "            # Store the data with 'Text' first, then 'Link'\n",
    "            all_links.append({'Text': text, 'Link': absolute_link_with_review})\n",
    "\n",
    "    return all_links\n",
    "\n",
    "# Main function to navigate through multiple pages and extract links\n",
    "async def extract_all_links(playwright):\n",
    "    all_links = []\n",
    "    browser = await playwright.chromium.launch(headless=False)\n",
    "    page = await browser.new_page()\n",
    "\n",
    "    # Load the webpage\n",
    "    url = 'https://www.bikewale.com/bajaj-bikes/'\n",
    "    await page.goto(url)\n",
    "\n",
    "    while True:\n",
    "        # Wait for the page content to load\n",
    "        await page.wait_for_timeout(2000)  # Adjust based on the page load time\n",
    "        page_content = await page.content()\n",
    "        \n",
    "        # Extract links from the current page\n",
    "        links_on_page = extract_links(page_content)\n",
    "        all_links.extend(links_on_page)\n",
    "        print(links_on_page)\n",
    "\n",
    "        # Check if the 'Next' button is available using the correct CSS selector\n",
    "        next_button = await page.query_selector(\"li.pagination__item.pagination__next-page > a\")\n",
    "\n",
    "        if next_button:\n",
    "            # Click the 'Next' button to go to the next page\n",
    "            await next_button.click()\n",
    "\n",
    "            # Wait for the content to load after clicking the button\n",
    "            await page.wait_for_timeout(2000)  # Adjust if necessary\n",
    "        else:\n",
    "            print(\"Next button not found, or no more pages. Exiting.\")\n",
    "            break\n",
    "\n",
    "    # Close the browser\n",
    "    await browser.close()\n",
    "\n",
    "    return all_links\n",
    "\n",
    "# Use Playwright to extract data\n",
    "async def main():\n",
    "    async with async_playwright() as playwright:\n",
    "        extracted_links = await extract_all_links(playwright)\n",
    "\n",
    "    # Move the extracted data to a DataFrame with columns in the desired order\n",
    "    df = pd.DataFrame(extracted_links, columns=['Text', 'Link'])\n",
    "\n",
    "    # Optionally, print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Optionally, save the DataFrame to a CSV file\n",
    "    df.to_csv('extracted_bikewale_links_playwright_async.csv', index=False)\n",
    "\n",
    "    print(\"Finished extracting the links and texts from all pages using Playwright.\")\n",
    "\n",
    "# Allow running asyncio within a Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the main function using the existing event loop\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
